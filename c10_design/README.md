# 贪婪算法

贪婪算法分阶段工作，每个阶段都做当下最好的决定，当算法终止时，我们希望局部最优解就是全局最优解。如果是这样的话，算法就是正确的，否则算法得到的是一个**次最优解（syboptimal solution）**。

所有调度问题都要么是 NP-完全的（或类似难度），要么是贪婪算法可解的。

### Huffman 编码

在字符编码的场景，如果字符集有 C 个字符，那么标准情况下每个字符需要占 LogC 个比特，我们记为 L。这里存在优化的条件：首先字符空间可能占不满，其次每个字符出现的频率可能不一样。

字符空间不满意味着两个连续的编码可以省略一位，比如 110 和 111，如果我们只需要一个编码的话，我们可以用 11 代表，而略去末位。这在编解码时也是没有歧义的。这种可变长度编码的数量为 `2^L - C` 个。然后我们要尽量把变长编码分配给常见字符。

分配变长编码的方式为使用 trie 树，这是一种二叉树，只在叶子节点分配编码，编码的值为从根开始到叶子节点的左右路径选择，比如左为 0，右为 1，则最左侧的节点编码为 000，最右为 111。配合上面的规则，我们就能分配出尽可能多的长度为 L-1 的编码，并分配给高频字符。编码歧义的消解可以这样理解：一个变长编码存在歧义当且仅当它是另一个编码的前缀。那么在 trie 树上，只要保持所有编码处在叶子节点，就没有歧义了。

这个方法主要的问题在于字符空间的空位数是不定的，甚至可能没有。如果我们更进一步地把变长编码发扬光大，不再遵循 LogC 的上限长度，而是完全按照字符分布创建出一棵 trie 树使每个字符的长度加权（出现频率）和最低，就可以把编码分配最优化。这种构建出来的树就是 Huffman 编码。

问题在于构建的算法，我们要构建一棵满树，但是深度不定。实际上最终树的深度取决于字符的概率分布，使用自根开始的方式生成树不知道该怎么做。这里应用贪婪算法，首先将所有字符看成单节点树，然后将这个森林合并成一棵满树。合并的规则是每次取总权重最低的两棵树作为子节点合并，权重等于该树上所有节点的字符频率的和。

### 近似装箱问题

给定 N 项物品，大小为 s1, s2, ... sn, 所有大小都满足 0 < si <= 1。问题是把这些物品装到最少数量的箱子中，已知箱子大小为 1。

算法分联机和脱机两种来讨论，显然联机算法不总能给出最优解，举一个特例即可说明。存在一个定理：

    存在使得任意联机装箱算法至少使用 4/3 最优箱子数的输入。

**首次适合算法（first fit）** 依序扫描已分配的箱子并将物品放入第一个能放下的箱子里。我们可以发现：在任一时刻最多有一个箱子其空出的部分大于箱子的一半，因为如果有两个，这两个箱子就应该合并。因此我们能够断言：首次适合算法最多使用最优解的 2 倍箱子数。而能证明的更好的界是 17/10（M）。

对于物品大小均匀分布的场景，统计值是首次适合算法平均比最优方法多 2% 的箱子。

**最佳适合算法（best fit）** 与首次的区别是：把物品放入能装下它的所有箱子中剩余空间最小的箱子。它的界是 M * 1.7。

因为至少我们可以通过穷举所有选项来找到最佳算法，因此脱机算法比联机算法至少存在理论上的改进。在联机算法中主要的问题是在后期出现的大箱子，因此在脱机算法中我们可以先给物品排序，再按联机算法装箱。且在物品已排序的情况下，首次适合算法与最佳适合算法的表现差不多。存在以下引理：

- 以递减排序输入物品时，首次适合算法放到最优解之外的箱子中的所有物品的大小最多为 1/3。反证法可证。
- 放入外加的箱子中的物品的个数最多是 M-1。
- 首次适合递减算法用的箱子数不超过 （4M+1）/3。
- 首次适合递减算法所用箱子数不超过 （11/9）*M + 4。

# 分治(devide and conquer)算法

分治算法由两部分组成：

- 分（devide）：递归解决较小的问题（基本情况除外）
- 治（conquer）：从子问题的解构建原问题的解

传统上，在代码中至少包含两个递归调用的例程才叫做分治算法，只有一个递归的不算。一般情况下子问题也是不相交的。

### 分治算法的运行时间

已知分步过程的运行时间，计算总的运行时间时有以下公式：

方程 `T(N) = a*T(N/b) + Θ(N^k)` 的解为:

- `O(N^logb(a)` 当 a > b^k
- `O(N^k*logN)` 当 a = b^k
- `O(N^k)` 当 a < b^k

其中 a>=1, b>1。

方程 T(N) = a*T(N/b) + Θ(N^k*(logN)^p) 的解为

- `O(N^logb(a))` 当 a > b^k
- `O(N^k*(logN)^(p+1))` 当 a = b^k
- `O(N^k*(logN)^p)` 当 a < b^k

其中 a>=1, b>1, p>=0。

### 最近点问题

给定平面上的一堆点 P 的坐标，计算距离最近的一对点。这个问题应用分治算法的思路是：把点集按 x 轴划分为两片，那么最近点就要么在左边，要么在右边，要么跨区。我们分别计算出左边和右边的最近点，再用计算结果缩小跨区场景的点集大小。

### 选择问题（selection problem）

选择问题即找出含有 N 个元素的表 S 中的第 k 个最小的元素，其中最难的问题是找出中间元素，即 k=N/2 时。

快排的一个变体可以用来解决这个问题，平均耗时 O(N)，但最坏耗时 O(N^2)，当 S 被排过序的时候。这里的关键是 pivot 的选择，需要一种能保证子问题比原问题小一定比例的 pivot 选择法，且其能够在更快的时间内完成。这里选择的是“五分化中项的中项”（median-of-median-of-five partitioning），即把 N 分为 5 个等大小的分片，然后分别计算中项，再取用这 5 个中项的中项。能够证明，此方法选出的中项最偏约为 N 的 70% 位置。且可以 O（N）选出。最后根据上面的运行时间算法，选择问题的总体时间为 O（N）。

这只是一个理论上的算法，实际跑起来时因为系统开销过多会比较慢。

# 动态规划(dynamic programming)

任何递归数学公式都可以直接翻译成递归程序，但事实上编译器经常无法正确对待递归算法，导致生成的程序低效。当出现这种情况时，我们需要把递归算法改进成非递归版本，使用的工具是一个能够记录子问题结果的表。动态规划就是应用此技术的一种过程。

### 使用表而非递归

这里其实与 SICP 的递归变迭代是一回事，基本表达式里有几个递归就需要保留几个变量，这些变量临时保存每次迭代时需要的递归值缓存。变量的存放方式应该没有特别的要求，可以用表也可以直接存本地变量。

### 全点对最短路径（All-Pairs Shortest Path）

使用动态规划计算有向图 G=(V, E) 中每一点对间赋权最短路径。Dijkstra 算法能够对稠密图以 O(V^2) 时间求解单点开始到所有其他顶点的最短路径，这里会提供一个算法以 O(len(V)^3) 计算所有点对的最短路径，且它在负值权重的场景下仍然工作，但 Dijkstra 算法不行。

回顾 Dijkstra 算法，它从顶点 s 开始分步骤工作，图中的每个顶点最终都会被作为中间顶点参与计算，假设当前选中的是 v，那么对于任一顶点 w 属于 V 且邻接 v，我们设 dw = min(dw, dv + c(v,w))，即说 s 到 w 的最短路径权重要么是已知的一个值，要么是 s 到 v 的路径权重再加上 v 直接到 w 的边的权重。

类似地，我们给顶点排序并依序选取顶点，定义 D(k,i,j) 为从 vi 到 vj 且只使用 v1, v2, ...,vk 为中间顶点的最短路径权重。且 D(0,i,j) = c(i,j)，同时如果 (vi, vj) 不是 G 的边，则 c(i,j) = 正无穷。根据定义可知：D(len(V),i,j) 即为从 vi 到 vj 的最短路径权重。

算法的实现即为对 D 表的更新，D 表是一个 len(V) x len(V) 的二维表，且 k 也要迭代从 1 到 len(V) 的值，因此全表的更新需要 O(len(V)^3) 时间。具体的计算公式为：

    D(k,i,j) = min{D(k-1,i,j), D(k-1,i,k) + D(k-1,k,j)}

动态规划体现在 min 里的值都是预存的而非递归计算的。

# 随机化算法（Randomized Algorithm）


