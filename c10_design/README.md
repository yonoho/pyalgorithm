# 贪婪算法

贪婪算法分阶段工作，每个阶段都做当下最好的决定，当算法终止时，我们希望局部最优解就是全局最优解。如果是这样的话，算法就是正确的，否则算法得到的是一个**次最优解（syboptimal solution）**。

所有调度问题都要么是 NP-完全的（或类似难度），要么是贪婪算法可解的。

### Huffman 编码

在字符编码的场景，如果字符集有 C 个字符，那么标准情况下每个字符需要占 LogC 个比特，我们记为 L。这里存在优化的条件：首先字符空间可能占不满，其次每个字符出现的频率可能不一样。

字符空间不满意味着两个连续的编码可以省略一位，比如 110 和 111，如果我们只需要一个编码的话，我们可以用 11 代表，而略去末位。这在编解码时也是没有歧义的。这种可变长度编码的数量为 `2^L - C` 个。然后我们要尽量把变长编码分配给常见字符。

分配变长编码的方式为使用 trie 树，这是一种二叉树，只在叶子节点分配编码，编码的值为从根开始到叶子节点的左右路径选择，比如左为 0，右为 1，则最左侧的节点编码为 000，最右为 111。配合上面的规则，我们就能分配出尽可能多的长度为 L-1 的编码，并分配给高频字符。编码歧义的消解可以这样理解：一个变长编码存在歧义当且仅当它是另一个编码的前缀。那么在 trie 树上，只要保持所有编码处在叶子节点，就没有歧义了。

这个方法主要的问题在于字符空间的空位数是不定的，甚至可能没有。如果我们更进一步地把变长编码发扬光大，不再遵循 LogC 的上限长度，而是完全按照字符分布创建出一棵 trie 树使每个字符的长度加权（出现频率）和最低，就可以把编码分配最优化。这种构建出来的树就是 Huffman 编码。

问题在于构建的算法，我们要构建一棵满树，但是深度不定。实际上最终树的深度取决于字符的概率分布，使用自根开始的方式生成树不知道该怎么做。这里应用贪婪算法，首先将所有字符看成单节点树，然后将这个森林合并成一棵满树。合并的规则是每次取总权重最低的两棵树作为子节点合并，权重等于该树上所有节点的字符频率的和。

### 近似装箱问题

给定 N 项物品，大小为 s1, s2, ... sn, 所有大小都满足 0 < si <= 1。问题是把这些物品装到最少数量的箱子中，已知箱子大小为 1。

算法分联机和脱机两种来讨论，显然联机算法不总能给出最优解，举一个特例即可说明。存在一个定理：

    存在使得任意联机装箱算法至少使用 4/3 最优箱子数的输入。

**首次适合算法（first fit）** 依序扫描已分配的箱子并将物品放入第一个能放下的箱子里。我们可以发现：在任一时刻最多有一个箱子其空出的部分大于箱子的一半，因为如果有两个，这两个箱子就应该合并。因此我们能够断言：首次适合算法最多使用最优解的 2 倍箱子数。而能证明的更好的界是 17/10（M）。

对于物品大小均匀分布的场景，统计值是首次适合算法平均比最优方法多 2% 的箱子。

**最佳适合算法（best fit）** 与首次的区别是：把物品放入能装下它的所有箱子中剩余空间最小的箱子。它的界是 M * 1.7。

因为至少我们可以通过穷举所有选项来找到最佳算法，因此脱机算法比联机算法至少存在理论上的改进。在联机算法中主要的问题是在后期出现的大箱子，因此在脱机算法中我们可以先给物品排序，再按联机算法装箱。且在物品已排序的情况下，首次适合算法与最佳适合算法的表现差不多。存在以下引理：

- 以递减排序输入物品时，首次适合算法放到最优解之外的箱子中的所有物品的大小最多为 1/3。反证法可证。
- 放入外加的箱子中的物品的个数最多是 M-1。
- 首次适合递减算法用的箱子数不超过 （4M+1）/3。
- 首次适合递减算法所用箱子数不超过 （11/9）*M + 4。

# 分治算法


