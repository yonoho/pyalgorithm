# 定义

### 二叉堆

当不加修饰地使用 “堆” 这个词的时候，默认指的是二叉堆。

堆是一棵被完全填充的树，唯一的例外是最底层，此层的数据也需要从左向右填充。这样的树叫做**完全二叉树**。因为完全二叉树的规律性，它可以表示为一个数组：对于数组任意位置 i 上的元素，其左子节点的坐标是 2i，右子节点的坐标是 2i + 1，它的父节点坐标是 i/2。因此，一个 **堆** 数据结构可以由一个数组、一个最大容量整数和一个当前容量整数组成。这叫做堆的结构性。它使得操作堆比操作树更快。

从结构性可以看出堆数组的下标是从 1 开始使用的。

堆同时需要有一个有序性，表述为：对于任意节点 X，其父节点的值都小于等于 X 的值。根节点除外，因为根节点没有父节点。

所有操作都需要满足以上两点性质。这里有个问题是：对于由一棵完全二叉树构成的堆，它有空穴吗？用下标描述就是：对于拥有 n 个元素的堆，它最后一个元素的下标等于 n 吗？解如下：

完全二叉树中深度为 h 的 所有节点，我们记为数组 N。其数量为 1 到 2**h 个，N 中元素的继承路径可以记为一个长度为 h 的数组，元素为 “左” 或者 “右”，我们记为 0 或 1。容易发现，这个数组正好等于元素在 N 中下标的二进制表示。

即：完全二叉树上深度为 h 的元素数组，下标为 k 的元素，其继承路径是 `bin(k)`，每个 0 转换成 “左”，每个 1 转换为 “右”。因为二叉树是完全的，该元素实际为整个树的第 `Σ(j=0,h-1)(2**j) + k + 1` 个元素，等于 `2**h + k`，等于在 bin(k) 的 h 位前面加了个 1。

而按继承路径计算它在堆中的下标为：

    def cal_position_in_heap(h: int, k: int):
        if h == k == 0:
            return None
        p = 1
        for i in bin(k)[2:].zfill(h):
            p *= 2
            if i == '1':
                p += 1
        return p

这个算法恰恰就是 `2**h + k` 按位加和的算法。也容易看出，不止二叉堆，对于任意 d-堆，其数组结构都是致密的。

##### 插入

因为存在结构性，插入时新空穴的位置是固定的，就是底层的最后一个元素或创建新的底层。如果这个空穴不能满足有序性，那么将其父节点挪到这个空穴，从而使父节点处产生新的空穴。这么做直到合适的空穴出现。这种操作名字叫**上滤**（percolate up）。上滤的有效性在于：节点下移总是不会破坏有序性。

##### 删除（最小元素）

同样从结构性出发，当根节点被删除时，最后一个位置的元素 X 需要空出来，然后放到正确的位置上。考虑有序性，空穴的较小子节点需要上移，直到能把 X 放入空穴。这个过程称为**下滤**（perlocate down）。

上滤和下滤就是把某个节点（空穴）看作滤网，分别向上和向下过滤（交换）直到找到合适的位置（满足有序性）。

#### 其他堆操作

堆本身含有的信息非常少，如果要实现其他操作，至少应该能通过其他数据结构拿到元素的位置。当位置可用时，又可以增加以下操作：

- DecreaseKey(P, V, H)：通过上滤将位置 P 的元素减小 V。
- IncreaseKey(P, V, H)：通过下滤将位置 P 的元素增大 V。
- Delete(P, H)：先通过 DecreaseKey(P, ∞, H) 把元素挪到顶部，再执行 DeleteMin
- BuildHeap(H)：将 N 个元素放入空堆中从而构建一个堆。可以通过 N 次插入实现，但最坏情形的复杂度为 O(NLogN)，而平均复杂度只有 O(N)。我们可以改变插入的做法来确保连续操作的边界不要那么坏。

一般方法是：先将 N 个关键字以任意顺序放入树中，只保持结构性。然后执行：

    for i in range(N//2, 0, -1):
        perlocateDown(i, H)

就可以实现有序性。

从 N/2 处开始的含义是：确保所有内部节点（非叶子节点）都执行了下滤。对于一个节点来说，执行过下滤后是可以保证它和它的子节点的有序性的。简单穷举三个元素的可能值就可以证明这一点。当所有内部节点都执行过下滤后，整棵树就全部都是有序的了。

因为下滤操作的极限执行次数等于节点的高，以上操作的最坏复杂度是整个树所有节点的高的和。这个值是 O(N)：

    定理：包含 (2**(k+1) - 1) 个节点，高为 k 的理想二叉树（perfect binary tree）的节点高的和是 (2**(k+1) - 1 - (b + 1))

#### Python 实现

内建库 heapq 已经实现了基本操作的接口。还提供了一些优化性能的联合操作，比如 `heapreplace(heap, item)` 和 `heappushpop(heap, item)`，这些函数比两个连续的独立操作要快。

# 合并

合并是将两个堆合并成一个的操作。因为在默认状况下需要将一个堆里所有元素插入到另一个堆而效率过低。因此出现了一些变种堆，主要目的是提高合并效率。在变种堆中为了避免实际的挪动节点的操作，会使用指针，这会带来一些效率的降低。

### 左式堆

左式堆和二叉堆的区别是：左式堆不是 理想平衡的（perfectly balaecd），而实际上是趋向于非常不平衡。

任一节点的**零路径长**定义为从该节点到一个**有空子节点**的节点的最短路径长。因此 **有空子节点**的节点的零路径长是 0。同时我们定义空节点的零路径长是 -1。

可见一个节点的零路径长等于其子节点零路径长的最小值 + 1。这个结论对 **有空子节点** 的节点也成立，因为我们定义了空节点的零路径长为 -1。

左式堆的性质是：对于堆中每个节点 X，其左子节点的零路径长**不小于**其右子节点。这个性质使得左式堆破坏了二叉堆的结构性，更容易向左偏。

因此如果想要找到左式堆里的一个空穴，向右查找是最快的。

定理：在右路径上有 r 个节点的左式树至少有 `2**r - 1` 个节点。可由归纳法证明。从此定理可得：有 N 个节点的左式树有一条路径最多含有  `Log(N+1)` 个节点。对左式堆操作的一般思路是将所有工作放到右路径上进行，它保证树深短。

#### 左式堆的操作

左式堆的基本操作是合并，插入被看成合并的一种特殊形式，即合并一个单节点堆。

上面说过，基本思路是把操作都放在右边。因此两个左式堆合并的过程是：

设需要合并的两个左式堆为 A 和 B。先比较两个堆根节点的大小，从而确定是 A 合并到 B 的右子树还是 B 合并到 A 的右子树。（应该让较大根值的堆合并到较小根值的堆的右子树上，以满足堆序性）

合并过程递归执行。且需保证生成的堆仍然是左式堆。

这样最终得到的结果是一个新的堆，但它很可能已经不是左式堆（因为一个堆完全合并到了另一个堆的右子树上）。此时，结果的左子树一定是左式堆，因为它全程没有发生变化，右子树也是左式堆，这是我们合并过程中的保证。因此只需要交换根节点的左右子树位置，这个堆就成了左式堆。

合并结束。

除了递归方法外，还有一种非递归合并方法。


##### 斜堆

略。

### 二项队列

略。
